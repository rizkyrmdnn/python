{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["> Nama : Rizky Ramdhani Koswara\n","\n","> NPM : 11122300\n","\n","> Kelas : 4KA25"],"metadata":{"id":"8AbLOqrQt2yq"}},{"cell_type":"markdown","source":["# 1. Import Library"],"metadata":{"id":"-FCRFZo9xl--"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-VgjWZrXxHtP"},"outputs":[],"source":["import tensorflow as tf"]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Dropout\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np"],"metadata":{"id":"Tf_3bvnZxjrX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 1. Import Library**\n","\n","**Logika Kode:**\n","Blok ini ngeberesin semua impor *library* yang dibutuhin.\n","* `tensorflow` diimpor sebagai `tf`, ini *framework* utamanya.\n","* `Tokenizer` dipake buat ngubah teks (kata-kata) jadi angka (token) biar bisa diproses model.\n","* `pad_sequences` dipake buat bikin semua urutan teks jadi sama panjang.\n","* `Embedding`, `LSTM`, `Dense`, `Bidirectional`, `Dropout` adalah lapisan-lapisan (layers) yang bakal kita pake buat ngebangun arsitektur model RNN kita. `LSTM` itu inti modelnya, `Bidirectional` bikin LST-nya bisa baca teks dari depan-belakang dan belakang-depan.\n","* `Sequential` adalah cara kita ngebangun modelnya, lapisan demi lapisan.\n","* `regularizers` dipake buat nambahin penalti ke *loss* biar model gak *overfitting*.\n","* `Adam` itu *optimizer* yang kita pake buat ngelatih model.\n","* `numpy` dipake buat ngurusin *array* angka.\n","\n","**Output/Efek:**\n","Gak ada *output* visual. Semua *library* dan modul yang dibutuhin jadi siap dipake di memori."],"metadata":{"id":"qPjRemnctRcF"}},{"cell_type":"markdown","source":["# 2. Mengunduh dataset shakesphere"],"metadata":{"id":"IF10fBfFx4-2"}},{"cell_type":"code","source":["!wget --no-check-certificate \\\n","  https://huggingface.co/arnavmahapatra/gpt2-sonnet-generators/blob/main/shakespeare.txt \\\n","  -O sonnets.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTcWV_oUx-HX","outputId":"68a38e24-0c2e-4f2c-af20-3faa62254673"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-15 08:29:47--  https://huggingface.co/arnavmahapatra/gpt2-sonnet-generators/blob/main/shakespeare.txt\n","Resolving huggingface.co (huggingface.co)... 18.238.109.102, 18.238.109.92, 18.238.109.52, ...\n","Connecting to huggingface.co (huggingface.co)|18.238.109.102|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1094068 (1.0M) [text/html]\n","Saving to: ‘sonnets.txt’\n","\n","sonnets.txt         100%[===================>]   1.04M  4.38MB/s    in 0.2s    \n","\n","2024-11-15 08:29:47 (4.38 MB/s) - ‘sonnets.txt’ saved [1094068/1094068]\n","\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 2. Mengunduh dataset shakesphere**\n","\n","**Logika Kode:**\n","Perintah `!wget` ini adalah perintah *shell* (bukan Python) buat ngunduh file dari internet.\n","* Dia ngambil file `shakespeare.txt` dari alamat URL di Hugging Face.\n","* `--no-check-certificate` dipake buat nge-*skip* verifikasi sertifikat SSL, jaga-jaga kalo ada masalah.\n","* `-O sonnets.txt` nyuruh `wget` buat nyimpen filenya dengan nama `sonnets.txt` di direktori kerja Colab kita.\n","\n","**Output/Efek:**\n","Outputnya nunjukkin proses *download* file. Kalo sukses, bakal ada tulisan kayak \"Saving to: ‘sonnets.txt’\" dan \"‘sonnets.txt’ saved\". Artinya, kita sekarang punya file teks `sonnets.txt` yang isinya karya-karya Shakespeare."],"metadata":{"id":"7Jf4ZhmEtTrF"}},{"cell_type":"markdown","source":["# 3. Mendefinisikan Tokenizer dan Menyiapkan Training Data\n","\n","Langkah  selanjutnya  yaitu  melakukan  proses  tokenisasi  dan  menyiapkan  data  yang  akan dilatih.  tokenisasi  adalah  proses  untuk  membagi  teks  yang  dapat  berupa  kalimat,  paragraf atau dokumen, menjadi token-token/bagian-bagian tertentu. Pada proses ini suatu kata yang ada pada  data sheet akan disimbolkan dengan angka secara acak sampai jumlah  kata yang ada  pada  datasheet  tersebut.  Pada  datasheet  ini  jumlah  katanya  yaitu  sampai  2900. Contohnya yaitu angka 1 didefinisikan untuk kata “and”, 2 untuk kata “the” dan seterusnya. Berikut adalah kodingan serta output dari proses tokenizer."],"metadata":{"id":"Tep7-1eazKla"}},{"cell_type":"code","source":["tokenizer = Tokenizer()\n","\n","data = open('sonnets.txt').read()\n","\n","corpus = data.lower().split('\\n')\n","\n","tokenizer.fit_on_texts(corpus)\n","total_words = len(tokenizer.word_index) + 1\n","\n","print(tokenizer.word_index)\n","print(total_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sgsUTHsrzSnZ","outputId":"10b7404f-ec16-4fd0-e14c-c3748c0bdb49"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'and': 1, 'the': 2, 'to': 3, 'of': 4, 'my': 5, 'i': 6, 'in': 7, 'that': 8, 'thy': 9, 'thou': 10, 'with': 11, 'for': 12, 'a': 13, 'but': 14, 'love': 15, 'is': 16, 'thee': 17, 'not': 18, 'me': 19, 'so': 20, 'you': 21, 'all': 22, 'be': 23, 'his': 24, 'when': 25, 'as': 26, 'which': 27, 'your': 28, 'this': 29, 'it': 30, 'doth': 31, 'by': 32, 'or': 33, 'do': 34, 'from': 35, 'then': 36, 'on': 37, 'no': 38, 'are': 39, 'their': 40, 'shall': 41, 'what': 42, 'have': 43, 'mine': 44, 'time': 45, 'if': 46, 'sweet': 47, 'more': 48, 'beauty': 49, 'art': 50, 'than': 51, 'where': 52, 'nor': 53, 'can': 54, 'should': 55, 'will': 56, 'now': 57, 'o': 58, 'how': 59, 'they': 60, 'he': 61, 'yet': 62, 'hath': 63, 'eyes': 64, 'make': 65, 'thine': 66, 'fair': 67, 'eye': 68, 'him': 69, 'one': 70, 'still': 71, 'like': 72, 'being': 73, 'every': 74, 'own': 75, 'praise': 76, 'some': 77, 'true': 78, 'such': 79, 'live': 80, 'heart': 81, 'see': 82, 'though': 83, 'day': 84, 'world': 85, 'were': 86, 'those': 87, 'give': 88, 'most': 89, 'was': 90, 'show': 91, 'may': 92, 'am': 93, 'say': 94, 'new': 95, 'dost': 96, 'her': 97, 'did': 98, 'even': 99, 'thyself': 100, 'look': 101, 'life': 102, 'these': 103, 'upon': 104, 'night': 105, 'since': 106, \"love's\": 107, 'myself': 108, 'worth': 109, 'old': 110, 'why': 111, 'at': 112, 'well': 113, 'might': 114, 'who': 115, 'must': 116, 'let': 117, 'thought': 118, 'would': 119, 'best': 120, 'thoughts': 121, \"beauty's\": 122, 'self': 123, 'days': 124, 'made': 125, 'dear': 126, 'truth': 127, 'muse': 128, 'part': 129, 'our': 130, 'too': 131, 'much': 132, 'she': 133, 'alone': 134, 'out': 135, 'away': 136, 'other': 137, 'verse': 138, 'ill': 139, 'better': 140, 'never': 141, 'an': 142, 'whose': 143, 'there': 144, 'up': 145, 'youth': 146, 'mind': 147, 'against': 148, 'find': 149, 'thus': 150, 'dead': 151, 'age': 152, 'nothing': 153, 'hand': 154, 'death': 155, 'sight': 156, \"time's\": 157, 'had': 158, 'good': 159, 'come': 160, 'first': 161, 'face': 162, 'each': 163, 'them': 164, 'before': 165, 'therefore': 166, 'both': 167, 'name': 168, 'ever': 169, 'die': 170, 'tell': 171, \"summer's\": 172, 'many': 173, 'none': 174, 'yourself': 175, 'long': 176, 'things': 177, 'far': 178, 'we': 179, 'bear': 180, 'bright': 181, 'making': 182, 'proud': 183, 'use': 184, 'form': 185, 'another': 186, 'leave': 187, 'hours': 188, 'gentle': 189, 'pleasure': 190, 'happy': 191, 'hast': 192, 'change': 193, 'kind': 194, 'mayst': 195, 'again': 196, 'know': 197, 'thing': 198, 'pen': 199, 'tongue': 200, 'earth': 201, 'false': 202, 'till': 203, 'seem': 204, \"'tis\": 205, 'woe': 206, 'take': 207, \"'\": 208, 'glass': 209, 'beauteous': 210, 'gone': 211, 'times': 212, 'could': 213, 'looks': 214, 'strong': 215, 'wilt': 216, 'end': 217, 'any': 218, 'decay': 219, 'whom': 220, \"o'er\": 221, 'after': 222, 'men': 223, 'state': 224, 'rich': 225, 'write': 226, 'grace': 227, 'whilst': 228, 'pride': 229, 'friend': 230, 'lie': 231, 'seen': 232, 'cannot': 233, 'lies': 234, 'within': 235, 'brow': 236, 'shame': 237, 'blood': 238, 'great': 239, 'nature': 240, 'lives': 241, 'summer': 242, 'place': 243, 'prove': 244, 'shalt': 245, 'others': 246, 'without': 247, 'hold': 248, 'heaven': 249, 'stay': 250, 'lines': 251, 'sun': 252, 'poor': 253, 'words': 254, 'think': 255, 'full': 256, 'loss': 257, 'deeds': 258, 'bring': 259, 'found': 260, 'spirit': 261, 'living': 262, 'desire': 263, 'memory': 264, 'fresh': 265, 'treasure': 266, 'lovely': 267, 'gives': 268, 'same': 269, 'leaves': 270, 'ten': 271, 'joy': 272, 'parts': 273, 'sing': 274, 'fear': 275, 'store': 276, 'save': 277, 'honour': 278, 'blessed': 279, 'lose': 280, 'glory': 281, 'once': 282, 'loving': 283, 'shadow': 284, 'although': 285, 'steal': 286, 'delight': 287, 'right': 288, 'thence': 289, 'set': 290, 'three': 291, 'forth': 292, 'rose': 293, 'else': 294, 'due': 295, 'child': 296, 'excuse': 297, 'cold': 298, 'back': 299, 'through': 300, 'dwell': 301, 'flowers': 302, 'ere': 303, 'light': 304, 'way': 305, 'unless': 306, 'sweets': 307, 'war': 308, 'ah': 309, 'keep': 310, 'hate': 311, \"'gainst\": 312, 'call': 313, 'green': 314, 'themselves': 315, 'grow': 316, 'eternal': 317, 'fortune': 318, 'read': 319, 'shows': 320, 'rhyme': 321, 'stand': 322, 'skill': 323, 'less': 324, 'sometime': 325, 'itself': 326, \"heaven's\": 327, 'breast': 328, 'dumb': 329, 'writ': 330, 'book': 331, 'rest': 332, 'view': 333, 'makes': 334, 'return': 335, 'disgrace': 336, 'wealth': 337, 'sad': 338, 'while': 339, \"i'll\": 340, 'speak': 341, 'whether': 342, 'argument': 343, 'heavy': 344, 'dull': 345, \"heart's\": 346, 'breath': 347, 'virtue': 348, 'only': 349, 'tender': 350, 'ornament': 351, 'spring': 352, 'waste': 353, 'pity': 354, 'deep': 355, 'tomb': 356, 'wrinkles': 357, 'golden': 358, \"nature's\": 359, 'canst': 360, 'very': 361, 'winter': 362, 'quite': 363, 'shouldst': 364, 'mortal': 365, 'chide': 366, 'shape': 367, 'year': 368, 'behold': 369, 'white': 370, 'barren': 371, 'hence': 372, 'longer': 373, 'yours': 374, 'rage': 375, 'stars': 376, 'painted': 377, 'outward': 378, 'graces': 379, 'antique': 380, 'swift': 381, 'wide': 382, 'worst': 383, 'wrong': 384, 'hue': 385, 'born': 386, 'strength': 387, 'wit': 388, 'wherein': 389, 'done': 390, 'buried': 391, 'hope': 392, 'scope': 393, 'precious': 394, \"stol'n\": 395, 'loved': 396, 'birth': 397, 'grief': 398, 'roses': 399, 'canker': 400, 'sweetest': 401, 'faults': 402, 'two': 403, 'loves': 404, 'spite': 405, 'lest': 406, 'into': 407, 'invention': 408, 'absence': 409, 'sake': 410, 'slow': 411, 'cheek': 412, 'slave': 413, 'been': 414, 'worse': 415, 'sin': 416, 'painting': 417, 'fears': 418, 'flower': 419, 'seeing': 420, 'bad': 421, 'spent': 422, 'increase': 423, 'sum': 424, 'calls': 425, 'prime': 426, 'despite': 427, 'single': 428, 'image': 429, 'lend': 430, 'lends': 431, 'given': 432, 'having': 433, 'unused': 434, 'frame': 435, 'play': 436, 'left': 437, 'substance': 438, \"death's\": 439, 'gracious': 440, 'head': 441, 'under': 442, 'weary': 443, 'hear': 444, 'mark': 445, 'song': 446, 'beloved': 447, 'fast': 448, 'gave': 449, 'gift': 450, 'go': 451, 'here': 452, 'judgment': 453, 'methinks': 454, 'doom': 455, 'date': 456, 'holds': 457, 'wish': 458, 'high': 459, 'numbers': 460, 'compare': 461, 'buds': 462, 'shade': 463, 'lived': 464, \"men's\": 465, 'fell': 466, 'rehearse': 467, 'air': 468, 'truly': 469, 'speaking': 470, 'public': 471, 'boast': 472, 'removed': 473, 'merit': 474, 'bare': 475, 'worthy': 476, 'toil': 477, 'tired': 478, 'black': 479, 'clouds': 480, 'moan': 481, 'appear': 482, 'base': 483, 'enough': 484, 'sorrow': 485, 'sense': 486, 'needs': 487, 'thief': 488, 'report': 489, 'subject': 490, 'leisure': 491, 'absent': 492, 'sleep': 493, 'down': 494, 'assured': 495, 'straight': 496, 'care': 497, 'need': 498, 'strange': 499, 'morrow': 500, 'second': 501, 'knife': 502, 'brass': 503, 'taught': 504, 'tongues': 505, 'rank': 506, 'sick': 507, 'grew': 508, 'story': 509, 'praises': 510, 'poet': 511, 'decease': 512, 'flame': 513, 'abundance': 514, 'cruel': 515, \"world's\": 516, 'grave': 517, 'weed': 518, 'answer': 519, 'count': 520, 'repair': 521, 'posterity': 522, 'april': 523, 'windows': 524, \"remember'd\": 525, 'spend': 526, 'used': 527, 'work': 528, 'effect': 529, \"distill'd\": 530, \"winter's\": 531, 'pay': 532, 'happier': 533, 'conquest': 534, 'worms': 535, 'heavenly': 536, 'son': 537, 'music': 538, 'receivest': 539, 'husband': 540, 'weep': 541, 'grant': 542, 'fairer': 543, 'least': 544, 'rude': 545, 'brave': 546, 'past': 547, 'beauties': 548, 'scythe': 549, 'takes': 550, 'lease': 551, 'pluck': 552, 'evil': 553, 'minutes': 554, 'oft': 555, 'knowledge': 556, 'constant': 557, 'wouldst': 558, 'nought': 559, 'height': 560, 'wear': 561, 'conceit': 562, 'virtuous': 563, 'inward': 564, 'keeps': 565, 'drawn': 566, 'believe': 567, \"fill'd\": 568, 'knows': 569, 'touches': 570, \"ne'er\": 571, 'shake': 572, 'course': 573, 'fade': 574, 'blunt': 575, 'burn': 576, 'forbid': 577, 'crime': 578, 'draw': 579, \"woman's\": 580, \"women's\": 581, 'man': 582, 'wert': 583, 'purpose': 584, 'moon': 585, 'rare': 586, 'cover': 587, 'gavest': 588, 'put': 589, 'burden': 590, 'body': 591, 'want': 592, 'frown': 593, 'fight': 594, 'forgot': 595, 'duty': 596, 'respect': 597, 'dare': 598, 'jewel': 599, 'farther': 600, 'blot': 601, 'flatter': 602, 'daily': 603, 'friends': 604, 'contented': 605, 'almost': 606, 'haply': 607, 'break': 608, 'account': 609, 'hearts': 610, 'survey': 611, 'brought': 612, 'style': 613, 'basest': 614, 'hide': 615, 'shine': 616, 'alack': 617, 'hour': 618, 'stain': 619, 'didst': 620, 'bears': 621, 'cross': 622, 'tears': 623, 'thorns': 624, 'sins': 625, 'fault': 626, 'plea': 627, 'twain': 628, 'dearest': 629, 'vulgar': 630, 'outlive': 631, 'manners': 632, 'blame': 633, 'taste': 634, 'greater': 635, 'injury': 636, 'said': 637, 'because': 638, 'gain': 639, 'losing': 640, 'flattery': 641, 'shadows': 642, 'clear': 643, 'matter': 644, 'foot': 645, 'sea': 646, 'fire': 647, 'present': 648, 'motion': 649, 'says': 650, \"eye's\": 651, 'took': 652, 'picture': 653, 'chest': 654, 'reasons': 655, 'desert': 656, 'seek': 657, 'speed': 658, 'pace': 659, 'tend': 660, 'odour': 661, 'hang': 662, 'stone': 663, 'quick': 664, 'edge': 665, 'former': 666, 'ocean': 667, 'shore': 668, 'doing': 669, 'hell': 670, 'character': 671, 'wonder': 672, 'main': 673, \"crown'd\": 674, 'mock': 675, 'home': 676, 'soul': 677, 'win': 678, 'power': 679, 'tied': 680, 'infection': 681, 'mend': 682, 'add': 683, 'smell': 684, 'common': 685, 'vile': 686, 'line': 687, 'birds': 688, 'brain': 689, 'acquaintance': 690, 'double': 691, \"others'\": 692, 'knowing': 693, 'fame': 694, 'sail': 695, 'saw': 696, 'silence': 697, 'above': 698, 'wretched': 699, \"what's\": 700, 'errors': 701, \"seem'd\": 702, 'lays': 703, 'growth': 704, 'colour': 705, 'confined': 706, \"'fair\": 707, 'just': 708, 'minds': 709, 'sonnets': 710, 'eternity': 711, 'wishing': 712, 't': 713, 'fairest': 714, 'thereby': 715, 'riper': 716, 'heir': 717, 'contracted': 718, 'bud': 719, 'content': 720, 'churl': 721, 'makest': 722, 'eat': 723, 'winters': 724, \"tatter'd\": 725, 'small': 726, 'held': 727, 'lusty': 728, \"'this\": 729, 'mother': 730, 'womb': 731, 'husbandry': 732, 'fond': 733, 'stop': 734, \"mother's\": 735, 'niggard': 736, 'abuse': 737, 'bounteous': 738, 'deceive': 739, 'audit': 740, 'gaze': 741, 'hideous': 742, 'confounds': 743, 'sap': 744, \"cheque'd\": 745, 'bareness': 746, 'remembrance': 747, 'meet': 748, 'willing': 749, 'breed': 750, 'depart': 751, 'lo': 752, 'sacred': 753, 'majesty': 754, 'resembling': 755, 'attending': 756, 'pilgrimage': 757, 'pitch': 758, 'converted': 759, 'going': 760, \"unlook'd\": 761, 'delights': 762, 'lovest': 763, 'married': 764, 'ear': 765, 'sweetly': 766, 'speechless': 767, 'seeming': 768, 'sings': 769, 'wail': 770, 'widow': 771, 'behind': 772, 'kept': 773, 'bosom': 774, 'himself': 775, 'murderous': 776, 'commits': 777, 'deny': 778, \"possess'd\": 779, 'chief': 780, 'presence': 781, 'growest': 782, 'folly': 783, 'bounty': 784, 'copy': 785, 'clock': 786, 'tells': 787, 'violet': 788, 'lofty': 789, 'borne': 790, 'question': 791, 'wastes': 792, 'forsake': 793, 'defence': 794, 'coming': 795, 'prepare': 796, 'issue': 797, 'father': 798, 'brief': 799, 'rain': 800, 'wind': 801, 'princes': 802, 'thrive': 803, 'grows': 804, 'perfection': 805, 'huge': 806, 'stage': 807, 'whereon': 808, 'influence': 809, 'comment': 810, 'youthful': 811, 'inconstant': 812, 'wasteful': 813, 'wherefore': 814, 'bloody': 815, 'tyrant': 816, 'fortify': 817, 'means': 818, 'maiden': 819, 'counterfeit': 820, 'pencil': 821, 'neither': 822, 'deserts': 823, 'half': 824, 'faces': 825, \"poet's\": 826, 'alive': 827, 'winds': 828, 'short': 829, 'hot': 830, 'shines': 831, 'often': 832, 'gold': 833, 'complexion': 834, 'changing': 835, 'breathe': 836, 'keen': 837, 'fierce': 838, 'glad': 839, 'seasons': 840, \"whate'er\": 841, 'allow': 842, 'pattern': 843, 'young': 844, 'master': 845, 'acquainted': 846, 'theirs': 847, 'gilding': 848, 'controlling': 849, 'souls': 850, 'woman': 851, 'created': 852, 'wrought': 853, \"fix'd\": 854, 'bearing': 855, 'babe': 856, 'besides': 857, 'replete': 858, 'trust': 859, 'forget': 860, 'perfect': 861, 'plead': 862, \"express'd\": 863, 'learn': 864, 'silent': 865, 'belongs': 866, 'fine': 867, 'painter': 868, 'turns': 869, 'therein': 870, 'favour': 871, 'triumph': 872, 'bars': 873, 'razed': 874, 'remove': 875, 'strongly': 876, 'send': 877, 'wanting': 878, \"soul's\": 879, 'star': 880, 'moving': 881, 'haste': 882, 'bed': 883, 'repose': 884, 'limbs': 885, 'travel': 886, 'journey': 887, 'abide': 888, 'eyelids': 889, 'open': 890, 'looking': 891, 'blind': 892, 'sightless': 893, 'hung': 894, 'benefit': 895, \"oppress'd\": 896, \"either's\": 897, 'reign': 898, 'hands': 899, 'off': 900, 'please': 901, 'sorrows': 902, 'nightly': 903, 'stronger': 904, 'curse': 905, \"man's\": 906, 'sullen': 907, 'hymns': 908, 'brings': 909, 'scorn': 910, 'kings': 911, 'lack': 912, 'hid': 913, 'expense': 914, \"vanish'd\": 915, 'heavily': 916, 'supposed': 917, 'holy': 918, 'interest': 919, 'survive': 920, 'dust': 921, 'deceased': 922, 'bettering': 923, 'reserve': 924, 'grown': 925, 'growing': 926, 'dearer': 927, 'died': 928, 'poets': 929, 'mountain': 930, 'sovereign': 931, 'pale': 932, 'alchemy': 933, 'anon': 934, 'ride': 935, 'stealing': 936, 'unseen': 937, 'west': 938, 'morn': 939, 'cloud': 940, \"mask'd\": 941, 'rotten': 942, 'weak': 943, 'ransom': 944, 'trespass': 945, 'amiss': 946, 'lawful': 947, 'sourly': 948, 'robs': 949, 'remain': 950, 'help': 951, 'evermore': 952, 'sort': 953, 'lame': 954, \"fortune's\": 955, 'comfort': 956, 'sit': 957, 'despised': 958, 'invent': 959, 'slight': 960, 'sour': 961, 'praising': 962, 'hadst': 963, 'blamed': 964, 'wilful': 965, 'robbery': 966, 'poverty': 967, 'lascivious': 968, 'kill': 969, 'foes': 970, 'petty': 971, 'wrongs': 972, 'liberty': 973, 'temptation': 974, 'seat': 975, 'try': 976, 'lead': 977, 'ye': 978, 'approve': 979, 'lay': 980, 'wink': 981, 'unrespected': 982, 'dreams': 983, 'dark': 984, 'clearer': 985, 'nights': 986, 'flesh': 987, 'injurious': 988, 'farthest': 989, 'soon': 990, 'large': 991, 'miles': 992, 'water': 993, 'elements': 994, 'told': 995, 'title': 996, 'either': 997, 'sure': 998, 'jewels': 999, 'prey': 1000, 'feel': 1001, 'whence': 1002, 'thievish': 1003, 'prize': 1004, 'cast': 1005, \"call'd\": 1006, 'strangely': 1007, 'pass': 1008, 'greet': 1009, 'cause': 1010, 'teach': 1011, 'beast': 1012, 'spur': 1013, 'groan': 1014, 'side': 1015, 'offence': 1016, 'horse': 1017, 'towards': 1018, 'seldom': 1019, 'captain': 1020, 'special': 1021, 'blest': 1022, \"imprison'd\": 1023, \"lack'd\": 1024, 'whereof': 1025, 'gilded': 1026, 'record': 1027, \"lover's\": 1028, 'force': 1029, 'appetite': 1030, 'feeding': 1031, 'fill': 1032, 'hungry': 1033, 'welcome': 1034, 'thrice': 1035, 'watch': 1036, 'bitterness': 1037, 'fool': 1038, 'god': 1039, 'control': 1040, 'bound': 1041, 'charter': 1042, 'privilege': 1043, 'belong': 1044, 'wait': 1045, 'subjects': 1046, 'goes': 1047, 'crooked': 1048, 'confound': 1049, 'shames': 1050, 'near': 1051, 'antiquity': 1052, \"age's\": 1053, 'king': 1054, 'cost': 1055, 'outworn': 1056, 'advantage': 1057, 'steel': 1058, 'ink': 1059, 'cry': 1060, 'forsworn': 1061, 'veins': 1062, 'last': 1063, 'map': 1064, 'shown': 1065, 'measure': 1066, 'weeds': 1067, 'suspect': 1068, 'crow': 1069, 'pure': 1070, \"pass'd\": 1071, 'tie': 1072, 'devise': 1073, 'untrue': 1074, 'yellow': 1075, \"ruin'd\": 1076, 'lost': 1077, 'peace': 1078, \"'twixt\": 1079, 'doubting': 1080, 'counting': 1081, 'possessing': 1082, 'compounds': 1083, 'noted': 1084, 'word': 1085, 'telling': 1086, 'dial': 1087, 'learning': 1088, 'got': 1089, 'ignorance': 1090, 'added': 1091, 'works': 1092, 'aid': 1093, 'humble': 1094, 'bark': 1095, 'worthless': 1096, 'monument': 1097, 'finding': 1098, 'anew': 1099, 'cheeks': 1100, 'quill': 1101, 'mute': 1102, 'comments': 1103, 'affords': 1104, 'praised': 1105, 'bonds': 1106, 'riches': 1107, 'comes': 1108, 'bending': 1109, 'vantage': 1110, 'bow': 1111, 'hawks': 1112, 'humour': 1113, 'finds': 1114, 'general': 1115, 'depends': 1116, 'deceived': 1117, 'sweetness': 1118, 'excellence': 1119, 'turn': 1120, 'sport': 1121, \"esteem'd\": 1122, \"deem'd\": 1123, 'autumn': 1124, 'dyed': 1125, 'neglect': 1126, 'seems': 1127, 'wondrous': 1128, 'constancy': 1129, \"true'\": 1130, \"look'd\": 1131, 'bred': 1132, 'frailties': 1133, 'alas': 1134, 'proved': 1135, 'proof': 1136, 'receives': 1137, 'drink': 1138, 'potions': 1139, 'bitter': 1140, 'strive': 1141, 'objects': 1142, 'palate': 1143, 'alters': 1144, 'shaken': 1145, 'unknown': 1146, 'taken': 1147, 'level': 1148, 'hopes': 1149, 'begetter': 1150, 'insuing': 1151, 'mr': 1152, 'w': 1153, 'h': 1154, 'happiness': 1155, 'promised': 1156, 'wisheth': 1157, 'adventurer': 1158, 'setting': 1159, 'creatures': 1160, \"feed'st\": 1161, \"light'st\": 1162, 'substantial': 1163, 'fuel': 1164, 'famine': 1165, 'foe': 1166, 'herald': 1167, 'gaudy': 1168, 'buriest': 1169, 'niggarding': 1170, 'glutton': 1171, 'ii': 1172, 'forty': 1173, 'beseige': 1174, 'dig': 1175, 'trenches': 1176, 'field': 1177, \"youth's\": 1178, 'livery': 1179, 'gazed': 1180, \"ask'd\": 1181, 'sunken': 1182, 'eating': 1183, 'thriftless': 1184, 'deserved': 1185, 'couldst': 1186, 'proving': 1187, 'succession': 1188, 'warm': 1189, \"feel'st\": 1190, 'iii': 1191, 'viewest': 1192, 'renewest': 1193, 'beguile': 1194, 'unbless': 1195, \"unear'd\": 1196, 'disdains': 1197, 'tillage': 1198, 'dies': 1199, 'iv': 1200, 'unthrifty': 1201, 'loveliness': 1202, 'legacy': 1203, 'bequest': 1204, 'frank': 1205, 'free': 1206, 'largess': 1207, 'profitless': 1208, 'usurer': 1209, 'sums': 1210, 'traffic': 1211, 'acceptable': 1212, \"tomb'd\": 1213, \"th'\": 1214, 'executor': 1215, 'v': 1216, 'tyrants': 1217, 'unfair': 1218, 'fairly': 1219, 'excel': 1220, 'resting': 1221, 'leads': 1222, 'frost': 1223, \"o'ersnow'd\": 1224, 'distillation': 1225, 'liquid': 1226, 'prisoner': 1227, 'pent': 1228, 'walls': 1229, 'bereft': 1230, 'leese': 1231, 'vi': 1232, 'ragged': 1233, 'deface': 1234, 'vial': 1235, \"kill'd\": 1236, 'forbidden': 1237, 'usury': 1238, 'happies': 1239, 'loan': 1240, \"that's\": 1241, 'refigured': 1242, 'leaving': 1243, \"will'd\": 1244, 'vii': 1245, 'orient': 1246, 'lifts': 1247, 'burning': 1248, 'homage': 1249, 'appearing': 1250, 'serving': 1251, \"climb'd\": 1252, 'steep': 1253, 'hill': 1254, 'middle': 1255, 'adore': 1256, 'highmost': 1257, 'car': 1258, 'feeble': 1259, 'reeleth': 1260, \"'fore\": 1261, 'duteous': 1262, 'low': 1263, 'tract': 1264, 'noon': 1265, 'diest': 1266, 'get': 1267, 'viii': 1268, \"hear'st\": 1269, 'sadly': 1270, 'gladly': 1271, 'annoy': 1272, 'concord': 1273, 'tuned': 1274, 'sounds': 1275, 'unions': 1276, 'offend': 1277, 'singleness': 1278, 'string': 1279, 'strikes': 1280, 'mutual': 1281, 'ordering': 1282, 'sire': 1283, 'pleasing': 1284, 'note': 1285, \"'thou\": 1286, 'ix': 1287, 'wet': 1288, \"widow's\": 1289, 'consumest': 1290, 'issueless': 1291, 'hap': 1292, 'makeless': 1293, 'wife': 1294, 'private': 1295, \"children's\": 1296, \"husband's\": 1297, 'unthrift': 1298, 'shifts': 1299, 'enjoys': 1300, 'user': 1301, 'destroys': 1302, 'toward': 1303, 'sits': 1304, 'x': 1305, \"bear'st\": 1306, 'unprovident': 1307, 'evident': 1308, \"stick'st\": 1309, 'conspire': 1310, 'seeking': 1311, 'roof': 1312, 'ruinate': 1313, 'lodged': 1314, 'hearted': 1315, 'xi': 1316, 'wane': 1317, 'departest': 1318, 'youngly': 1319, 'bestowest': 1320, 'convertest': 1321, 'herein': 1322, 'wisdom': 1323, 'minded': 1324, 'cease': 1325, 'threescore': 1326, 'harsh': 1327, 'featureless': 1328, 'barrenly': 1329, 'perish': 1330, \"endow'd\": 1331, 'cherish': 1332, 'carved': 1333, 'seal': 1334, 'meant': 1335, 'print': 1336, 'xii': 1337, 'sunk': 1338, 'sable': 1339, 'curls': 1340, \"silver'd\": 1341, 'trees': 1342, 'erst': 1343, 'heat': 1344, 'canopy': 1345, 'herd': 1346, 'girded': 1347, 'sheaves': 1348, 'bier': 1349, 'bristly': 1350, 'beard': 1351, 'among': 1352, 'xiii': 1353, 'semblance': 1354, 'determination': 1355, \"yourself's\": 1356, 'lets': 1357, 'house': 1358, 'fall': 1359, 'uphold': 1360, 'stormy': 1361, 'gusts': 1362, 'unthrifts': 1363, 'xiv': 1364, 'astronomy': 1365, 'luck': 1366, 'plagues': 1367, 'dearths': 1368, \"seasons'\": 1369, 'quality': 1370, 'pointing': 1371, 'thunder': 1372, 'predict': 1373, 'derive': 1374, 'together': 1375, 'convert': 1376, 'prognosticate': 1377, \"truth's\": 1378, 'xv': 1379, 'consider': 1380, 'little': 1381, 'moment': 1382, 'presenteth': 1383, 'secret': 1384, 'perceive': 1385, 'plants': 1386, 'cheered': 1387, 'sky': 1388, 'vaunt': 1389, 'decrease': 1390, 'sets': 1391, 'debateth': 1392, 'sullied': 1393, 'engraft': 1394, 'xvi': 1395, 'mightier': 1396, 'top': 1397, 'gardens': 1398, 'unset': 1399, 'liker': 1400, 'pupil': 1401, 'xvii': 1402, 'hides': 1403, 'number': 1404, \"touch'd\": 1405, 'earthly': 1406, 'papers': 1407, \"yellow'd\": 1408, \"scorn'd\": 1409, 'rights': 1410, \"term'd\": 1411, 'stretched': 1412, 'metre': 1413, 'twice': 1414, 'xviii': 1415, 'temperate': 1416, 'rough': 1417, 'darling': 1418, \"dimm'd\": 1419, 'declines': 1420, 'chance': 1421, \"untrimm'd\": 1422, 'possession': 1423, 'owest': 1424, 'brag': 1425, \"wander'st\": 1426, 'xix': 1427, 'devouring': 1428, \"lion's\": 1429, 'paws': 1430, 'devour': 1431, 'brood': 1432, 'teeth': 1433, \"tiger's\": 1434, 'jaws': 1435, 'phoenix': 1436, 'sorry': 1437, 'fleets': 1438, 'footed': 1439, 'fading': 1440, 'heinous': 1441, 'carve': 1442, 'untainted': 1443, 'succeeding': 1444, 'xx': 1445, 'mistress': 1446, 'passion': 1447, 'shifting': 1448, 'fashion': 1449, 'rolling': 1450, 'object': 1451, 'whereupon': 1452, 'gazeth': 1453, \"'hues'\": 1454, 'steals': 1455, 'amazeth': 1456, 'doting': 1457, 'addition': 1458, 'defeated': 1459, 'adding': 1460, \"prick'd\": 1461, 'xxi': 1462, \"stirr'd\": 1463, 'couplement': 1464, \"sea's\": 1465, 'gems': 1466, \"april's\": 1467, 'rondure': 1468, 'hems': 1469, \"o'\": 1470, 'candles': 1471, 'hearsay': 1472, 'sell': 1473, 'xxii': 1474, 'persuade': 1475, 'furrows': 1476, 'expiate': 1477, 'seemly': 1478, 'raiment': 1479, 'elder': 1480, 'wary': 1481, 'chary': 1482, 'nurse': 1483, 'faring': 1484, 'presume': 1485, 'slain': 1486, 'xxiii': 1487, 'unperfect': 1488, 'actor': 1489, \"strength's\": 1490, 'weakens': 1491, 'ceremony': 1492, 'rite': 1493, \"o'ercharged\": 1494, 'books': 1495, 'eloquence': 1496, 'presagers': 1497, 'recompense': 1498, 'xxiv': 1499, \"play'd\": 1500, \"stell'd\": 1501, 'table': 1502, 'perspective': 1503, \"painter's\": 1504, 'pictured': 1505, \"bosom's\": 1506, 'shop': 1507, 'hanging': 1508, 'glazed': 1509, 'peep': 1510, 'cunning': 1511, 'xxv': 1512, 'titles': 1513, \"princes'\": 1514, 'favourites': 1515, 'spread': 1516, 'marigold': 1517, \"sun's\": 1518, 'painful': 1519, 'warrior': 1520, 'famoused': 1521, 'thousand': 1522, 'victories': 1523, \"foil'd\": 1524, \"toil'd\": 1525, 'xxvi': 1526, 'lord': 1527, 'vassalage': 1528, 'knit': 1529, 'written': 1530, 'embassage': 1531, 'witness': 1532, 'naked': 1533, 'bestow': 1534, 'whatsoever': 1535, 'guides': 1536, 'points': 1537, 'graciously': 1538, 'aspect': 1539, 'puts': 1540, 'apparel': 1541, 'xxvii': 1542, 'begins': 1543, \"body's\": 1544, \"work's\": 1545, 'expired': 1546, 'intend': 1547, 'zealous': 1548, 'drooping': 1549, 'darkness': 1550, 'imaginary': 1551, 'presents': 1552, 'ghastly': 1553, 'quiet': 1554, 'xxviii': 1555, 'plight': 1556, \"debarr'd\": 1557, \"day's\": 1558, 'oppression': 1559, 'eased': 1560, 'enemies': 1561, 'consent': 1562, 'torture': 1563, 'complain': 1564, 'swart': 1565, \"complexion'd\": 1566, 'sparkling': 1567, 'twire': 1568, \"gild'st\": 1569, \"grief's\": 1570, 'xxix': 1571, 'beweep': 1572, 'outcast': 1573, 'trouble': 1574, 'deal': 1575, 'bootless': 1576, 'cries': 1577, 'fate': 1578, 'featured': 1579, 'desiring': 1580, 'enjoy': 1581, 'despising': 1582, 'lark': 1583, 'arising': 1584, 'gate': 1585, 'xxx': 1586, 'sessions': 1587, 'summon': 1588, 'sigh': 1589, 'sought': 1590, 'woes': 1591, 'drown': 1592, 'flow': 1593, 'dateless': 1594, 'afresh': 1595, \"cancell'd\": 1596, 'grieve': 1597, 'grievances': 1598, 'foregone': 1599, 'fore': 1600, 'bemoaned': 1601, 'paid': 1602, 'losses': 1603, 'restored': 1604, 'xxxi': 1605, 'endeared': 1606, 'lacking': 1607, 'reigns': 1608, 'obsequious': 1609, 'tear': 1610, 'religious': 1611, 'hidden': 1612, 'trophies': 1613, 'lovers': 1614, 'images': 1615, 'xxxii': 1616, 'bones': 1617, 're': 1618, 'lover': 1619, \"outstripp'd\": 1620, 'exceeded': 1621, 'vouchsafe': 1622, \"'had\": 1623, \"friend's\": 1624, 'march': 1625, 'ranks': 1626, 'equipage': 1627, 'xxxiii': 1628, 'glorious': 1629, 'morning': 1630, 'tops': 1631, 'kissing': 1632, 'meadows': 1633, 'streams': 1634, 'permit': 1635, 'ugly': 1636, 'rack': 1637, 'celestial': 1638, 'forlorn': 1639, 'visage': 1640, 'early': 1641, 'triumphant': 1642, 'splendor': 1643, 'region': 1644, 'whit': 1645, 'disdaineth': 1646, 'suns': 1647, 'staineth': 1648, 'xxxiv': 1649, 'promise': 1650, 'cloak': 1651, \"o'ertake\": 1652, 'hiding': 1653, 'bravery': 1654, 'smoke': 1655, 'dry': 1656, 'storm': 1657, 'beaten': 1658, 'salve': 1659, 'heals': 1660, 'wound': 1661, 'cures': 1662, 'physic': 1663, 'repent': 1664, \"offender's\": 1665, 'relief': 1666, \"offence's\": 1667, 'pearl': 1668, 'sheds': 1669, 'xxxv': 1670, 'grieved': 1671, 'silver': 1672, 'fountains': 1673, 'mud': 1674, 'eclipses': 1675, 'loathsome': 1676, 'authorizing': 1677, 'corrupting': 1678, 'salving': 1679, 'excusing': 1680, 'sensual': 1681, 'adverse': 1682, 'party': 1683, 'advocate': 1684, 'commence': 1685, 'civil': 1686, 'accessary': 1687, 'xxxvi': 1688, 'confess': 1689, 'undivided': 1690, 'blots': 1691, 'separable': 1692, 'alter': 1693, 'sole': 1694, 'acknowledge': 1695, 'bewailed': 1696, 'guilt': 1697, 'kindness': 1698, 'xxxvii': 1699, 'decrepit': 1700, 'active': 1701, 'entitled': 1702, 'crowned': 1703, 'engrafted': 1704, 'sufficed': 1705, 'xxxviii': 1706, \"pour'st\": 1707, 'excellent': 1708, 'paper': 1709, 'thanks': 1710, 'aught': 1711, 'perusal': 1712, \"who's\": 1713, 'tenth': 1714, 'nine': 1715, 'rhymers': 1716, 'invocate': 1717, 'curious': 1718, 'pain': 1719, 'xxxix': 1720, \"'t\": 1721, 'us': 1722, 'divided': 1723, 'separation': 1724, 'deservest': 1725, 'torment': 1726, 'entertain': 1727, 'teachest': 1728, 'xl': 1729, 'yea': 1730, 'usest': 1731, 'deceivest': 1732, 'refusest': 1733, 'forgive': 1734, \"hate's\": 1735, 'known': 1736, 'spites': 1737, 'xli': 1738, 'years': 1739, 'befits': 1740, 'follows': 1741, 'won': 1742, 'assailed': 1743, 'woos': 1744, 'prevailed': 1745, 'ay': 1746, 'mightest': 1747, 'forbear': 1748, 'straying': 1749, 'riot': 1750, 'forced': 1751, 'twofold': 1752, 'hers': 1753, 'tempting': 1754, 'xlii': 1755, 'dearly': 1756, 'wailing': 1757, 'nearly': 1758, 'offenders': 1759, 'knowst': 1760, 'suffering': 1761, \"here's\": 1762, 'xliii': 1763, 'darkly': 1764, 'directed': 1765, \"shadow's\": 1766, 'unseeing': 1767, 'imperfect': 1768, 'xliv': 1769, 'distance': 1770, 'space': 1771, 'limits': 1772, 'remote': 1773, 'nimble': 1774, 'jump': 1775, 'land': 1776, 'kills': 1777, 'leap': 1778, 'lengths': 1779, 'attend': 1780, 'receiving': 1781, 'badges': 1782, 'xlv': 1783, 'purging': 1784, 'wherever': 1785, 'slide': 1786, 'quicker': 1787, 'embassy': 1788, 'four': 1789, 'sinks': 1790, 'melancholy': 1791, 'until': 1792, \"life's\": 1793, 'composition': 1794, 'recured': 1795, 'messengers': 1796, \"return'd\": 1797, 'health': 1798, 'recounting': 1799, 'xlvi': 1800, 'divide': 1801, \"picture's\": 1802, 'bar': 1803, 'freedom': 1804, 'closet': 1805, 'pierced': 1806, 'crystal': 1807, 'defendant': 1808, 'appearance': 1809, \"'cide\": 1810, 'impanneled': 1811, 'quest': 1812, 'tenants': 1813, 'verdict': 1814, 'determined': 1815, 'moiety': 1816, 'xlvii': 1817, 'betwixt': 1818, 'league': 1819, 'unto': 1820, \"famish'd\": 1821, 'sighs': 1822, 'smother': 1823, 'feast': 1824, 'banquet': 1825, 'bids': 1826, 'guest': 1827, 'share': 1828, 'resent': 1829, 'move': 1830, 'awakes': 1831, 'xlviii': 1832, 'careful': 1833, 'trifle': 1834, 'truest': 1835, 'thrust': 1836, 'falsehood': 1837, 'wards': 1838, 'trifles': 1839, 'greatest': 1840, \"lock'd\": 1841, 'closure': 1842, 'proves': 1843, 'xlix': 1844, 'defects': 1845, 'utmost': 1846, 'advised': 1847, 'respects': 1848, 'scarcely': 1849, 'settled': 1850, 'gravity': 1851, 'ensconce': 1852, 'uprear': 1853, 'guard': 1854, 'laws': 1855, 'allege': 1856, 'l': 1857, \"travel's\": 1858, 'ease': 1859, \"'thus\": 1860, 'measured': 1861, 'plods': 1862, 'dully': 1863, 'weight': 1864, 'instinct': 1865, 'wretch': 1866, 'rider': 1867, 'provoke': 1868, 'sometimes': 1869, 'anger': 1870, 'thrusts': 1871, 'answers': 1872, 'sharp': 1873, 'spurring': 1874, 'onward': 1875, 'li': 1876, 'bearer': 1877, 'posting': 1878, 'extremity': 1879, 'mounted': 1880, 'winged': 1881, \"perfect'st\": 1882, 'neigh': 1883, 'fiery': 1884, 'race': 1885, 'jade': 1886, 'went': 1887, 'run': 1888, 'lii': 1889, 'key': 1890, 'locked': 1891, 'blunting': 1892, 'point': 1893, 'feasts': 1894, 'solemn': 1895, 'stones': 1896, 'thinly': 1897, 'placed': 1898, 'carcanet': 1899, 'wardrobe': 1900, 'robe': 1901, 'instant': 1902, 'unfolding': 1903, 'worthiness': 1904, 'liii': 1905, 'millions': 1906, 'describe': 1907, 'adonis': 1908, 'poorly': 1909, 'imitated': 1910, \"helen's\": 1911, 'grecian': 1912, 'tires': 1913, 'foison': 1914, 'external': 1915, 'liv': 1916, 'deem': 1917, 'blooms': 1918, 'dye': 1919, 'perfumed': 1920, 'tincture': 1921, 'wantonly': 1922, 'masked': 1923, 'discloses': 1924, \"unwoo'd\": 1925, 'deaths': 1926, 'odours': 1927, 'distills': 1928, 'lv': 1929, 'marble': 1930, 'monuments': 1931, 'powerful': 1932, 'contents': 1933, 'unswept': 1934, \"besmear'd\": 1935, 'sluttish': 1936, 'statues': 1937, 'overturn': 1938, 'broils': 1939, 'root': 1940, 'masonry': 1941, 'mars': 1942, 'sword': 1943, \"war's\": 1944, 'oblivious': 1945, 'enmity': 1946, 'room': 1947, 'ending': 1948, 'arise': 1949, 'lvi': 1950, 'renew': 1951, 'blunter': 1952, \"allay'd\": 1953, \"sharpen'd\": 1954, 'fullness': 1955, 'perpetual': 1956, 'dullness': 1957, 'interim': 1958, 'banks': 1959, \"wish'd\": 1960, 'lvii': 1961, 'services': 1962, 'require': 1963, 'bid': 1964, 'servant': 1965, 'adieu': 1966, 'jealous': 1967, 'affairs': 1968, 'suppose': 1969, 'thinks': 1970, 'lviii': 1971, 'crave': 1972, 'vassal': 1973, 'suffer': 1974, 'beck': 1975, 'patience': 1976, 'tame': 1977, 'sufferance': 1978, 'bide': 1979, 'cheque': 1980, 'accusing': 1981, 'list': 1982, 'pardon': 1983, 'waiting': 1984, 'lix': 1985, 'brains': 1986, 'beguiled': 1987, 'labouring': 1988, 'backward': 1989, 'five': 1990, 'hundred': 1991, 'courses': 1992, 'composed': 1993, 'mended': 1994, 'revolution': 1995, 'wits': 1996, 'admiring': 1997, 'lx': 1998, 'waves': 1999, 'pebbled': 2000, 'hasten': 2001, 'sequent': 2002, 'forwards': 2003, 'contend': 2004, 'nativity': 2005, 'crawls': 2006, 'maturity': 2007, 'wherewith': 2008, 'elipses': 2009, 'transfix': 2010, 'flourish': 2011, 'delves': 2012, 'parallels': 2013, 'feeds': 2014, 'rarities': 2015, 'stands': 2016, 'mow': 2017, 'lxi': 2018, 'slumbers': 2019, 'broken': 2020, \"send'st\": 2021, 'pry': 2022, 'idle': 2023, 'tenor': 2024, 'jealousy': 2025, 'awake': 2026, 'defeat': 2027, 'watchman': 2028, 'wake': 2029, 'elsewhere': 2030, 'lxii': 2031, 'possesseth': 2032, 'remedy': 2033, 'grounded': 2034, 'define': 2035, 'worths': 2036, 'surmount': 2037, 'indeed': 2038, 'beated': 2039, \"chopp'd\": 2040, \"tann'd\": 2041, 'contrary': 2042, 'iniquity': 2043, 'lxiii': 2044, \"crush'd\": 2045, 'worn': 2046, \"drain'd\": 2047, \"travell'd\": 2048, 'steepy': 2049, \"he's\": 2050, 'vanishing': 2051, 'confounding': 2052, 'cut': 2053, 'lxiv': 2054, 'defaced': 2055, 'towers': 2056, 'kingdom': 2057, 'firm': 2058, 'soil': 2059, 'watery': 2060, 'increasing': 2061, 'interchange': 2062, 'confounded': 2063, 'ruin': 2064, 'ruminate': 2065, 'choose': 2066, 'lxv': 2067, 'boundless': 2068, 'mortality': 2069, 'sways': 2070, 'action': 2071, 'honey': 2072, 'wreckful': 2073, 'siege': 2074, 'battering': 2075, 'rocks': 2076, 'impregnable': 2077, 'stout': 2078, 'gates': 2079, 'decays': 2080, 'fearful': 2081, 'meditation': 2082, 'spoil': 2083, 'miracle': 2084, 'lxvi': 2085, 'restful': 2086, 'beggar': 2087, 'needy': 2088, \"trimm'd\": 2089, 'jollity': 2090, 'purest': 2091, 'faith': 2092, 'unhappily': 2093, 'guilded': 2094, 'shamefully': 2095, 'misplaced': 2096, 'rudely': 2097, 'strumpeted': 2098, 'wrongfully': 2099, 'disgraced': 2100, 'limping': 2101, 'sway': 2102, 'disabled': 2103, 'authority': 2104, 'doctor': 2105, 'simple': 2106, \"miscall'd\": 2107, 'simplicity': 2108, 'captive': 2109, 'lxvii': 2110, 'impiety': 2111, 'achieve': 2112, 'lace': 2113, 'society': 2114, 'imitate': 2115, 'indirectly': 2116, 'bankrupt': 2117, \"beggar'd\": 2118, 'blush': 2119, 'lively': 2120, 'exchequer': 2121, 'gains': 2122, 'stores': 2123, 'lxviii': 2124, 'bastard': 2125, 'signs': 2126, 'durst': 2127, 'inhabit': 2128, 'tresses': 2129, 'sepulchres': 2130, 'shorn': 2131, 'fleece': 2132, 'gay': 2133, \"another's\": 2134, 'robbing': 2135, 'dress': 2136, 'yore': 2137, 'lxix': 2138, 'voice': 2139, 'uttering': 2140, 'commend': 2141, 'accents': 2142, 'guess': 2143, 'churls': 2144, 'matcheth': 2145, 'solve': 2146, 'lxx': 2147, 'defect': 2148, \"slander's\": 2149, 'flies': 2150, 'slander': 2151, \"woo'd\": 2152, 'vice': 2153, \"present'st\": 2154, 'unstained': 2155, 'ambush': 2156, \"assail'd\": 2157, 'victor': 2158, 'charged': 2159, 'envy': 2160, 'enlarged': 2161, 'kingdoms': 2162, 'owe': 2163, 'lxxi': 2164, 'mourn': 2165, 'surly': 2166, 'bell': 2167, 'warning': 2168, 'fled': 2169, 'vilest': 2170, 'nay': 2171, 'remember': 2172, 'thinking': 2173, 'perhaps': 2174, 'compounded': 2175, 'clay': 2176, 'wise': 2177, 'lxxii': 2178, 'task': 2179, 'recite': 2180, 'willingly': 2181, 'impart': 2182, 'shamed': 2183, 'lxxiii': 2184, 'few': 2185, 'boughs': 2186, 'choirs': 2187, 'late': 2188, 'sang': 2189, 'seest': 2190, 'twilight': 2191, 'sunset': 2192, 'fadeth': 2193, 'seals': 2194, \"see'st\": 2195, 'glowing': 2196, 'ashes': 2197, 'expire': 2198, 'consumed': 2199, \"nourish'd\": 2200, 'perceivest': 2201, 'lxxiv': 2202, 'arrest': 2203, 'bail': 2204, 'carry': 2205, 'memorial': 2206, 'reviewest': 2207, 'review': 2208, 'consecrate': 2209, 'dregs': 2210, 'coward': 2211, \"wretch's\": 2212, 'remembered': 2213, 'contains': 2214, 'remains': 2215, 'lxxv': 2216, 'food': 2217, \"season'd\": 2218, 'showers': 2219, 'ground': 2220, 'strife': 2221, 'miser': 2222, 'enjoyer': 2223, 'filching': 2224, \"better'd\": 2225, 'feasting': 2226, 'clean': 2227, 'starved': 2228, 'pursuing': 2229, 'pine': 2230, 'surfeit': 2231, 'gluttoning': 2232, 'lxxvi': 2233, 'variation': 2234, 'glance': 2235, 'aside': 2236, 'methods': 2237, 'showing': 2238, 'proceed': 2239, 'always': 2240, 'dressing': 2241, 'spending': 2242, 'already': 2243, 'lxxvii': 2244, 'vacant': 2245, \"mind's\": 2246, 'imprint': 2247, 'mouthed': 2248, 'graves': 2249, \"dial's\": 2250, 'shady': 2251, 'stealth': 2252, 'progress': 2253, 'contain': 2254, 'commit': 2255, 'blanks': 2256, 'children': 2257, 'nursed': 2258, \"deliver'd\": 2259, 'offices': 2260, 'profit': 2261, 'enrich': 2262, 'lxxviii': 2263, 'invoked': 2264, 'assistance': 2265, 'alien': 2266, 'poesy': 2267, 'disperse': 2268, 'aloft': 2269, 'fly': 2270, 'feathers': 2271, \"learned's\": 2272, 'wing': 2273, 'compile': 2274, 'arts': 2275, 'graced': 2276, 'advance': 2277, 'lxxix': 2278, \"decay'd\": 2279, 'deserves': 2280, 'travail': 2281, 'worthier': 2282, 'pays': 2283, 'stole': 2284, 'behavior': 2285, 'afford': 2286, 'thank': 2287, 'owes': 2288, 'lxxx': 2289, 'faint': 2290, 'thereof': 2291, 'spends': 2292, 'proudest': 2293, 'saucy': 2294, 'inferior': 2295, 'broad': 2296, 'wilfully': 2297, 'shallowest': 2298, 'afloat': 2299, 'soundless': 2300, \"wreck'd\": 2301, 'boat': 2302, 'tall': 2303, 'building': 2304, 'goodly': 2305, 'lxxxi': 2306, 'epitaph': 2307, 'forgotten': 2308, 'immortal': 2309, 'yield': 2310, 'entombed': 2311, 'breathers': 2312, 'breathes': 2313, 'mouths': 2314, 'lxxxii': 2315, 'attaint': 2316, \"o'erlook\": 2317, 'dedicated': 2318, 'writers': 2319, 'blessing': 2320, 'limit': 2321, 'enforced': 2322, 'fresher': 2323, 'stamp': 2324, 'devised': 2325, 'strained': 2326, 'rhetoric': 2327, 'sympathized': 2328, 'plain': 2329, 'gross': 2330, 'abused': 2331, 'lxxxiii': 2332, 'exceed': 2333, 'debt': 2334, 'slept': 2335, 'extant': 2336, 'modern': 2337, 'impute': 2338, 'impair': 2339, 'lxxxiv': 2340, 'confine': 2341, 'immured': 2342, 'example': 2343, 'equal': 2344, 'lean': 2345, 'penury': 2346, 'writes': 2347, 'dignifies': 2348, 'counterpart': 2349, 'admired': 2350, 'blessings': 2351, 'lxxxv': 2352, 'richly': 2353, 'compiled': 2354, 'phrase': 2355, 'muses': 2356, 'filed': 2357, \"unletter'd\": 2358, 'clerk': 2359, \"'amen'\": 2360, 'hymn': 2361, 'able': 2362, \"polish'd\": 2363, 'refined': 2364, 'hearing': 2365, \"''tis\": 2366, 'something': 2367, 'hindmost': 2368, 'lxxxvi': 2369, 'ripe': 2370, 'inhearse': 2371, 'spirits': 2372, 'struck': 2373, 'compeers': 2374, 'giving': 2375, 'astonished': 2376, 'affable': 2377, 'familiar': 2378, 'ghost': 2379, 'gulls': 2380, 'intelligence': 2381, 'victors': 2382, 'countenance': 2383, 'enfeebled': 2384, 'lxxxvii': 2385, 'farewell': 2386, \"know'st\": 2387, 'estimate': 2388, 'releasing': 2389, 'determinate': 2390, 'granting': 2391, 'deserving': 2392, 'patent': 2393, 'swerving': 2394, 'mistaking': 2395, 'misprision': 2396, 'dream': 2397, 'waking': 2398, 'lxxxviii': 2399, 'disposed': 2400, 'weakness': 2401, \"conceal'd\": 2402, 'attainted': 2403, 'gainer': 2404, 'injuries': 2405, 'lxxxix': 2406, 'lameness': 2407, 'halt': 2408, 'desired': 2409, 'strangle': 2410, 'walks': 2411, 'profane': 2412, 'vow': 2413, 'debate': 2414, 'xc': 2415, 'bent': 2416, 'join': 2417, 'drop': 2418, \"'scoped\": 2419, 'rearward': 2420, \"conquer'd\": 2421, 'windy': 2422, 'rainy': 2423, 'linger': 2424, 'purposed': 2425, 'overthrow': 2426, 'griefs': 2427, 'onset': 2428, 'strains': 2429, 'compared': 2430, 'xci': 2431, \"bodies'\": 2432, 'garments': 2433, 'fangled': 2434, 'hounds': 2435, 'adjunct': 2436, 'particulars': 2437, 'richer': 2438, 'prouder': 2439, \"garments'\": 2440, 'horses': 2441, 'xcii': 2442, 'term': 2443, 'depend': 2444, 'vex': 2445, 'revolt': 2446, 'xciii': 2447, 'supposing': 2448, \"alter'd\": 2449, 'hatred': 2450, \"many's\": 2451, 'history': 2452, 'moods': 2453, 'frowns': 2454, 'creation': 2455, 'decree': 2456, 'workings': 2457, \"eve's\": 2458, 'apple': 2459, 'xciv': 2460, 'hurt': 2461, 'unmoved': 2462, 'rightly': 2463, 'inherit': 2464, 'lords': 2465, 'owners': 2466, 'stewards': 2467, 'outbraves': 2468, 'dignity': 2469, 'sourest': 2470, 'lilies': 2471, 'fester': 2472, 'xcv': 2473, 'fragrant': 2474, 'spot': 2475, 'budding': 2476, 'enclose': 2477, 'dispraise': 2478, 'naming': 2479, 'blesses': 2480, 'mansion': 2481, 'vices': 2482, 'habitation': 2483, 'chose': 2484, 'veil': 2485, 'heed': 2486, 'hardest': 2487, 'xcvi': 2488, 'wantonness': 2489, 'resort': 2490, 'finger': 2491, 'throned': 2492, 'queen': 2493, 'truths': 2494, 'translated': 2495, 'lambs': 2496, 'stem': 2497, 'wolf': 2498, 'betray': 2499, 'lamb': 2500, 'translate': 2501, 'gazers': 2502, 'mightst': 2503, 'xcvii': 2504, 'fleeting': 2505, 'freezings': 2506, 'felt': 2507, \"december's\": 2508, 'teeming': 2509, 'big': 2510, 'wanton': 2511, \"widow'd\": 2512, 'wombs': 2513, \"lords'\": 2514, 'abundant': 2515, 'orphans': 2516, \"unfather'd\": 2517, 'fruit': 2518, 'pleasures': 2519, 'cheer': 2520, 'dreading': 2521, 'xcviii': 2522, 'pied': 2523, \"dress'd\": 2524, 'trim': 2525, 'saturn': 2526, \"laugh'd\": 2527, \"leap'd\": 2528, 'different': 2529, 'lap': 2530, \"lily's\": 2531, 'vermilion': 2532, 'figures': 2533, 'xcix': 2534, 'forward': 2535, 'smells': 2536, 'purple': 2537, 'soft': 2538, 'dwells': 2539, 'grossly': 2540, 'lily': 2541, 'condemned': 2542, 'marjoram': 2543, 'hair': 2544, 'fearfully': 2545, 'blushing': 2546, 'despair': 2547, 'third': 2548, 'red': 2549, \"annex'd\": 2550, 'theft': 2551, 'vengeful': 2552, 'c': 2553, \"forget'st\": 2554, \"spend'st\": 2555, 'fury': 2556, 'darkening': 2557, 'forgetful': 2558, 'redeem': 2559, 'idly': 2560, 'esteem': 2561, 'rise': 2562, 'resty': 2563, 'wrinkle': 2564, 'graven': 2565, 'satire': 2566, 'spoils': 2567, 'faster': 2568, \"prevent'st\": 2569, 'ci': 2570, 'truant': 2571, 'amends': 2572, 'dignified': 2573, \"'truth\": 2574, \"intermix'd\": 2575, \"for't\": 2576, 'ages': 2577, 'office': 2578, 'cii': 2579, \"strengthen'd\": 2580, 'merchandized': 2581, 'esteeming': 2582, \"owner's\": 2583, 'publish': 2584, 'wont': 2585, 'philomel': 2586, 'front': 2587, 'stops': 2588, 'pipe': 2589, 'pleasant': 2590, 'mournful': 2591, 'hush': 2592, 'wild': 2593, 'burthens': 2594, 'bough': 2595, 'ciii': 2596, 'beside': 2597, 'appears': 2598, 'over': 2599, 'dulling': 2600, 'sinful': 2601, 'striving': 2602, 'mar': 2603, 'verses': 2604, 'gifts': 2605, 'civ': 2606, 'eyed': 2607, 'forests': 2608, 'shook': 2609, \"summers'\": 2610, 'springs': 2611, \"turn'd\": 2612, 'process': 2613, 'perfumes': 2614, 'junes': 2615, \"burn'd\": 2616, 'figure': 2617, 'perceived': 2618, 'unbred': 2619, 'cv': 2620, 'idolatry': 2621, 'idol': 2622, 'alike': 2623, 'songs': 2624, 'expressing': 2625, 'difference': 2626, 'varying': 2627, 'themes': 2628, 'cvi': 2629, 'chronicle': 2630, 'wasted': 2631, 'descriptions': 2632, 'wights': 2633, 'beautiful': 2634, 'ladies': 2635, 'knights': 2636, 'blazon': 2637, 'lip': 2638, 'prophecies': 2639, 'prefiguring': 2640, 'divining': 2641, 'cvii': 2642, 'prophetic': 2643, 'dreaming': 2644, 'forfeit': 2645, 'eclipse': 2646, 'endured': 2647, 'augurs': 2648, 'presage': 2649, 'incertainties': 2650, 'crown': 2651, 'proclaims': 2652, 'olives': 2653, 'endless': 2654, 'drops': 2655, 'balmy': 2656, 'subscribes': 2657, 'insults': 2658, 'tribes': 2659, \"tyrants'\": 2660, 'crests': 2661, 'tombs': 2662, 'cviii': 2663, 'figured': 2664, 'register': 2665, 'express': 2666, 'boy': 2667, 'prayers': 2668, 'divine': 2669, \"hallow'd\": 2670, 'case': 2671, 'weighs': 2672, 'necessary': 2673, 'aye': 2674, 'page': 2675, 'cix': 2676, 'qualify': 2677, 'easy': 2678, 'ranged': 2679, 'travels': 2680, 'exchanged': 2681, \"reign'd\": 2682, 'besiege': 2683, 'kinds': 2684, 'preposterously': 2685, \"stain'd\": 2686, 'universe': 2687, 'cx': 2688, 'motley': 2689, 'gored': 2690, 'sold': 2691, 'cheap': 2692, 'offences': 2693, 'affections': 2694, 'askance': 2695, 'blenches': 2696, 'essays': 2697, 'grind': 2698, 'newer': 2699, 'older': 2700, 'next': 2701, 'cxi': 2702, 'guilty': 2703, 'goddess': 2704, 'harmful': 2705, 'provide': 2706, 'breeds': 2707, 'brand': 2708, 'subdued': 2709, \"dyer's\": 2710, \"renew'd\": 2711, 'patient': 2712, 'eisel': 2713, 'penance': 2714, 'correct': 2715, 'correction': 2716, 'assure': 2717, 'cure': 2718, 'cxii': 2719, 'impression': 2720, 'scandal': 2721, \"stamp'd\": 2722, \"steel'd\": 2723, 'changes': 2724, 'profound': 2725, 'abysm': 2726, 'throw': 2727, 'voices': 2728, \"adder's\": 2729, 'critic': 2730, 'flatterer': 2731, 'stopped': 2732, 'dispense': 2733, 'cxiii': 2734, 'governs': 2735, 'about': 2736, 'function': 2737, 'partly': 2738, 'effectually': 2739, 'delivers': 2740, 'bird': 2741, 'latch': 2742, 'vision': 2743, 'catch': 2744, 'rudest': 2745, 'gentlest': 2746, \"deformed'st\": 2747, 'creature': 2748, 'dove': 2749, 'shapes': 2750, 'feature': 2751, 'incapable': 2752, 'cxiv': 2753, \"monarch's\": 2754, 'plague': 2755, 'saith': 2756, 'monsters': 2757, 'indigest': 2758, 'cherubins': 2759, 'resemble': 2760, 'creating': 2761, 'beams': 2762, 'assemble': 2763, 'kingly': 2764, 'drinks': 2765, 'gust': 2766, \"'greeing\": 2767, 'cup': 2768, \"poison'd\": 2769, 'lesser': 2770, 'begin': 2771, 'cxv': 2772, 'knew': 2773, 'reason': 2774, 'afterwards': 2775, 'reckoning': 2776, \"million'd\": 2777, 'accidents': 2778, 'creep': 2779, 'vows': 2780, 'decrees': 2781, 'tan': 2782, \"sharp'st\": 2783, 'intents': 2784, 'divert': 2785, 'altering': 2786, 'fearing': 2787, 'tyranny': 2788, \"'now\": 2789, 'certain': 2790, 'incertainty': 2791, 'crowning': 2792, 'cxvi': 2793, 'marriage': 2794, 'admit': 2795, 'impediments': 2796, 'alteration': 2797, 'bends': 2798, 'remover': 2799, 'fixed': 2800, 'tempests': 2801, 'wandering': 2802, \"worth's\": 2803, 'rosy': 2804, 'lips': 2805, \"sickle's\": 2806, 'compass': 2807, 'weeks': 2808, 'error': 2809, 'cxvii': 2810, 'accuse': 2811, 'scanted': 2812, 'repay': 2813, 'whereto': 2814, 'frequent': 2815, 'purchased': 2816, 'hoisted': 2817, 'transport': 2818, 'wilfulness': 2819, 'surmise': 2820, 'accumulate': 2821, 'shoot': 2822, \"waken'd\": 2823, 'appeal': 2824, 'cxviii': 2825, 'appetites': 2826, 'eager': 2827, 'urge': 2828, 'prevent': 2829, 'maladies': 2830, 'sicken': 2831, 'shun': 2832, 'sickness': 2833, 'purge': 2834, 'tuff': 2835, 'cloying': 2836, 'sauces': 2837, 'welfare': 2838, 'meetness': 2839, 'diseased': 2840, 'needing': 2841, 'policy': 2842, 'anticipate': 2843, 'ills': 2844, 'medicine': 2845, 'healthful': 2846, 'goodness': 2847, 'cured': 2848, 'lesson': 2849, 'drugs': 2850, 'poison': 2851, 'cxix': 2852, 'drunk': 2853, 'siren': 2854, 'limbecks': 2855, 'foul': 2856, 'applying': 2857, 'committed': 2858, 'spheres': 2859, 'fitted': 2860, 'distraction': 2861, 'madding': 2862, 'fever': 2863, 'built': 2864, 'rebuked': 2865, 'cxx': 2866, 'unkind': 2867, 'befriends': 2868, 'transgression': 2869, 'nerves': 2870, \"hammer'd\": 2871, 'unkindness': 2872, \"you've\": 2873, 'weigh': 2874, 'suffered': 2875, 'deepest': 2876, 'hard': 2877, 'hits': 2878, \"tender'd\": 2879, 'wounded': 2880, 'bosoms': 2881, 'fits': 2882, 'becomes': 2883, 'fee': 2884, 'ransoms': 2885, 'cxxi': 2886, 'reproach': 2887, 'feeling': 2888, 'adulterate': 2889, 'salutation': 2890, 'sportive': 2891, 'frailer': 2892, 'spies': 2893, 'wills': 2894, 'abuses': 2895, 'reckon': 2896, 'bevel': 2897, 'maintain': 2898, 'badness': 2899}\n","2900\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 3. Mendefinisikan Tokenizer dan Menyiapkan Training Data**\n","\n","**Logika Kode:**\n","Ini adalah langkah krusial buat nyiapin data teks mentah jadi data *training* yang siap dipake model.\n","1.  `tokenizer = Tokenizer()`: Bikin objek *tokenizer* baru.\n","2.  `data = open('sonnets.txt').read()`: Ngebaca semua isi file `sonnets.txt` ke dalam satu *string* gede.\n","3.  `corpus = data.lower().split('\\n')`: Ngebersihin data. `lower()` ngubah semua teks jadi huruf kecil (biar \"The\" dan \"the\" dianggap sama). `split('\\n')` mecah teks jadi daftar (list) berdasarkan baris baru. Jadi, `corpus` sekarang isinya *list* dari tiap baris puisi.\n","4.  `tokenizer.fit_on_texts(corpus)`: Ini \"ngelatih\" *tokenizer*-nya. Dia ngebaca semua baris di `corpus` dan bikin \"kamus\" (`word_index`) dari semua kata unik yang dia temuin.\n","5.  `total_words = len(tokenizer.word_index) + 1`: Ngitung jumlah total kata unik. Ditambah 1 buat nge-handle *padding* (token 0) nanti.\n","6.  `print(tokenizer.word_index)`: Nampilin kamus yang udah dibuat.\n","7.  `print(total_words)`: Nampilin jumlah total kata unik + 1.\n","\n","**Output/Efek:**\n","* Output pertama adalah `word_index`, yaitu kamus kata-ke-angka. Contohnya `{'and': 1, 'the': 2, 'to': 3, ...}`. Ini nunjukkin kata yang paling sering muncul dapet angka (indeks) kecil.\n","* Output kedua adalah jumlah total kata unik plus satu, di contoh ini 2900."],"metadata":{"id":"jScZOHXItZ2u"}},{"cell_type":"code","source":["input_sequences = []\n","\n","for line in corpus:\n","  token_list = tokenizer.texts_to_sequences ([line])[0]\n","  #print(\"LIST\"+str(token_list))\n","  for i in range(1, len(token_list)):\n","    n_gram_sequence = token_list[:i+1]\n","    input_sequences.append(n_gram_sequence)\n","\n","\n","##pad sequences\n","max_sequence_len = max([len(seq) for seq in input_sequences])\n","\n","print(max_sequence_len, total_words)\n","\n","input_sequences = np.array(pad_sequences(input_sequences, padding='pre', maxlen=max_sequence_len))\n","\n","#create predictors and labels\n","xs, labels = input_sequences[:,:-1], input_sequences[:,-1]\n","\n","ys = tf.keras.utils.to_categorical (labels, num_classes=total_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AqhYIlFa0h3w","outputId":"2bbdc2e0-e888-4bdc-9e25-da749b9dd425"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["11 2900\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: (Lanjutan) Penyiapan Data Sequence**\n","\n","**Logika Kode:**\n","Setelah punya kamus, kita harus ubah teks jadi urutan angka buat *training*. Tujuannya adalah *word prediction*: dari beberapa kata sebelumnya, tebak satu kata berikutnya.\n","1.  `input_sequences = []`: Bikin *list* kosong buat nyimpen semua urutan data.\n","2.  `for line in corpus:`: Nge-*loop* tiap baris puisi di `corpus`.\n","3.  `token_list = tokenizer.texts_to_sequences([line])[0]`: Ngubah satu baris puisi (misal: \"from fairest creatures\") jadi urutan angka (misal: `[35, 714, 1160]`).\n","4.  `for i in range(1, len(token_list)):`: Ini bagian penting. Dia bikin *n-gram* atau sub-kalimat. Kalo urutannya `[35, 714, 1160]`, dia bakal bikin:\n","    * `[35, 714]` (input: \"from\", target: \"fairest\")\n","    * `[35, 714, 1160]` (input: \"from fairest\", target: \"creatures\")\n","5.  `input_sequences.append(n_gram_sequence)`: Masukin semua sub-kalimat tadi ke `input_sequences`.\n","6.  `max_sequence_len = max([...])`: Nyari tau urutan terpanjang dari semua sub-kalimat yang kita buat.\n","7.  `input_sequences = np.array(pad_sequences(...))`: Bikin semua urutan di `input_sequences` jadi sama panjang (sepanjang `max_sequence_len`). `padding='pre'` nambahin angka 0 di *depan* urutan yang lebih pendek.\n","8.  `xs, labels = ...`: Mecah data. `xs` (input) adalah semua token *kecuali* yang terakhir. `labels` (target) adalah *cuma* token terakhir.\n","9.  `ys = tf.keras.utils.to_categorical(...)`: Ngubah `labels` (yang cuma satu angka, misal `1160`) jadi format *one-hot encoding*. Jadi *array* sepanjang `total_words` (2900) yang isinya 0 semua kecuali di indeks ke-1160 yang nilainya 1. Ini format yang dibutuhin buat *loss* `categorical_crossentropy`.\n","\n","**Output/Efek:**\n","* Nge-print `max_sequence_len` (11) dan `total_words` (2900).\n","* Variabel `xs` dan `ys` sekarang siap dipake buat *training*. `xs` bentuknya (jumlah_urutan, 10) dan `ys` bentuknya (jumlah_urutan, 2900)."],"metadata":{"id":"RHzYfV4Nta6o"}},{"cell_type":"markdown","source":["# 4. Mendefinisikan Arsitektur Model\n","\n","Langkah selanjutnya yaitu mendefinisikan arsitektur , pada tahap ini kita menentukan berapa total kata yang ada pada artikel tersebut kemudian menentukan urutan setiap kata yang ada pada  artikel  tersebut.  Berikut  adalah  kodingan  serta  output  dari  mendefinisikan  arsitektur modelnya."],"metadata":{"id":"9vpybTtd3PX0"}},{"cell_type":"code","source":["model = Sequential()\n","model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n","model.add(Bidirectional(LSTM(150, return_sequences=True)))\n","model.add(Dropout(0.3))\n","model.add(Bidirectional(LSTM(96)))\n","model.add(Dense(total_words//2, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n","model.add(Dense(total_words, activation='softmax'))\n","\n","print(model.summary())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":389},"id":"8WeuOA873W2b","outputId":"7c9ee2b7-a65c-4b9a-e918-ffd0ba6c2e4d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_6\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ embedding_6 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_12 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_13 (\u001b[38;5;33mBidirectional\u001b[0m)     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ embedding_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ bidirectional_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["None\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 4. Mendefinisikan Arsitektur Model**\n","\n","**Logika Kode:**\n","Ini bagian ngebangun arsitektur model LSTM-nya pake `Sequential`.\n","1.  `Embedding(total_words, 100, ...)`: *Layer* pertama. Ini ngubah tiap kata (angka token) di input `xs` jadi vektor 100 dimensi. Ini cara model belajar \"arti\" dan hubungan antar kata.\n","2.  `Bidirectional(LSTM(150, return_sequences=True))`: *Layer* LSTM bolak-balik (Bidirectional) dengan 150 unit. `return_sequences=True` artinya dia ngeluarin *output* buat tiap token di urutan, bukan cuma *output* terakhir. Ini perlu karena kita mau numpuk *layer* LSTM lagi.\n","3.  `Dropout(0.3)`: *Layer* *dropout* buat ngebuang 30% koneksi neuron secara acak pas *training*. Ini buat ngurangin *overfitting*.\n","4.  `Bidirectional(LSTM(96))`: *Layer* LSTM bolak-balik kedua. Yang ini `return_sequences`-nya *default* (False), jadi dia cuma ngeluarin satu *output* di akhir urutan.\n","5.  `Dense(total_words//2, ...)`: *Layer* `Dense` biasa. `kernel_regularizer=regularizers.l2(0.01)` nambahin L2 *regularization* buat bantu cegah *overfitting* lagi.\n","6.  `Dense(total_words, activation='softmax')`: *Layer* *output* terakhir. Harus punya neuron sebanyak `total_words` (2900). Aktivasi `softmax` bakal ngasih probabilitas buat tiap kata di kamus, nunjukkin kata mana yang paling mungkin jadi kata berikutnya.\n","7.  `print(model.summary())`: Nampilin ringkasan arsitektur model.\n","\n","**Output/Efek:**\n","* Outputnya adalah ringkasan model (`model.summary()`). Harusnya nunjukkin daftar *layer*, bentuk *output*, dan jumlah parameter. *Catatan: Output di notebook lo nunjukkin \"unbuilt\" karena modelnya belum dikasih data, tapi setelah di-compile dan di-fit, summary-nya bakal bener.*"],"metadata":{"id":"FsnvneHotfnD"}},{"cell_type":"markdown","source":["# 5. Training Data"],"metadata":{"id":"Cu0xzwf_-tAU"}},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","history = model.fit(xs, ys, epochs=100, verbose=1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8AxHBeDE-q1h","outputId":"b1ed5c05-4b1e-44dd-a9f7-cf3a77ca9c96"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 143ms/step - accuracy: 0.0237 - loss: 7.7045\n","Epoch 2/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 145ms/step - accuracy: 0.0209 - loss: 6.4439\n","Epoch 3/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 139ms/step - accuracy: 0.0265 - loss: 6.3765\n","Epoch 4/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 138ms/step - accuracy: 0.0268 - loss: 6.3082\n","Epoch 5/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 137ms/step - accuracy: 0.0316 - loss: 6.2169\n","Epoch 6/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 139ms/step - accuracy: 0.0419 - loss: 6.0480\n","Epoch 7/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 142ms/step - accuracy: 0.0393 - loss: 5.9812\n","Epoch 8/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 147ms/step - accuracy: 0.0433 - loss: 5.9233\n","Epoch 9/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 137ms/step - accuracy: 0.0506 - loss: 5.7860\n","Epoch 10/10\n","\u001b[1m380/380\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 135ms/step - accuracy: 0.0470 - loss: 5.7064\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 5. Training Data**\n","\n","**Logika Kode:**\n","Ini proses ngelatih model yang udah kita bikin.\n","1.  `model.compile(...)`: Nyatuin model. Kita tentuin *loss function*-nya (`categorical_crossentropy`, cocok buat klasifikasi multi-kelas pake *softmax*), *optimizer*-nya (`adam`), dan metrik yang mau diliat (`accuracy`).\n","2.  `history = model.fit(xs, ys, epochs=100, verbose=1)`: Ini dia perintah buat mulai *training*.\n","    * `xs`: Data input (urutan kata).\n","    * `ys`: Data target (kata berikutnya, udah di-*one-hot encode*).\n","    * `epochs=100`: Ngulang proses *training* di seluruh dataset sebanyak 100 kali. Di *notebook* lo, ini di-*run* cuma 10 *epoch*.\n","    * `verbose=1`: Nampilin *progress bar* dan metrik buat tiap *epoch*.\n","\n","**Output/Efek:**\n","* Outputnya adalah *log* proses *training*. Buat tiap *epoch* (dari 10), dia bakal nunjukkin *progress bar*, waktu yang dibutuhin, nilai `loss`, dan `accuracy`.\n","* Contoh: `Epoch 1/10 380/380 [...] - accuracy: 0.0237 - loss: 7.7045`.\n","* Akurasi awalnya pasti kecil banget karena nebak 1 dari 2900 kata itu susah. Seiring *epoch* berjalan, akurasinya harusnya naik dan *loss*-nya turun."],"metadata":{"id":"ErFogquytkJe"}},{"cell_type":"markdown","source":["# 6. Membuat Perintah Untuk 100 Kata Selanjutnya\n","\n","Langkah selanjutnya yaitu membuat perintah untuk RNN supaya dapat memprediksi 100kata selanjutnya pada artikel yang ingin dibuat berdasarkan datasheet yang sudah diunduh pada langkah sebelumnya. Pada langkah ini RNN akan dipancing untuk memprediksi kataselanjutnya berdasarkan seed textyang sudah ditentukan sebelumnya."],"metadata":{"id":"FyhPa38RFc2Q"}},{"cell_type":"code","source":["def predict_next_words(seed_text, next_words):\n","  for _ in range(next_words):\n","    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n","    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n","    predict_x = model.predict(token_list)\n","    predicted = np.argmax(predict_x,axis=1)\n","    #predicted model.predict_classes(token list, verbose-8)\n","    output_word = \"\"\n","    for word, index in tokenizer.word_index.items():\n","      if index == predicted:\n","        output_word = word\n","        break\n","    seed_text += \" \" + output_word\n","\n","  print(seed_text)\n","  return seed_text"],"metadata":{"id":"esA1hlW9FgxQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 6. Membuat Perintah Untuk 100 Kata Selanjutnya**\n","\n","**Logika Kode:**\n","Ini definisi fungsi `predict_next_words` buat nge-tes model kita. Fungsi ini bakal nge-generasi teks baru.\n","1.  `for _ in range(next_words):`: Nge-*loop* sebanyak `next_words` (misal 100 kali).\n","2.  `token_list = tokenizer.texts_to_sequences([seed_text])[0]`: Ngubah `seed_text` (teks awal) jadi urutan angka.\n","3.  `token_list = pad_sequences(...)`: Nyiapin inputnya. Di-*padding* di depan biar panjangnya pas (10 token) kayak data `xs`.\n","4.  `predict_x = model.predict(token_list)`: Ini dia prediksinya. Model ngasih *output* probabilitas buat 2900 kata.\n","5.  `predicted = np.argmax(predict_x,axis=1)`: Milih kata dengan probabilitas tertinggi. `np.argmax` ngambil indeks (angka token) dari kata yang paling mungkin.\n","6.  `for word, index in tokenizer.word_index.items():`: Nge-*loop* kamus.\n","7.  `if index == predicted:`: Kalo indeksnya cocok sama hasil prediksi, kita nemu katanya.\n","8.  `output_word = word`: Simpen katanya.\n","9.  `seed_text += \" \" + output_word`: Nambahin kata yang baru ditebak ke `seed_text`.\n","10. *Loop* tadi ngulang lagi, tapi sekarang `seed_text`-nya udah lebih panjang satu kata. Modelnya jadi nebak kata berikutnya berdasarkan teks yang baru ditambahin.\n","11. `print(seed_text)`: Setelah *loop* 100 kali selesai, *print* hasil akhirnya.\n","\n","**Output/Efek:**\n","Gak ada *output* pas sel ini dijalanin, karena ini cuma definisi fungsi."],"metadata":{"id":"zSJEiN06tmx3"}},{"cell_type":"markdown","source":["# 7. Output Artikel dengan Seed Text"],"metadata":{"id":"uvYSluZoHSym"}},{"cell_type":"code","source":["seed_text = '1THREEPIO'\n","next_words = 100\n","\n","generated_text = predict_next_words(seed_text, next_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"58dGdNCJJEJ0","outputId":"f536c75b-5d5a-43e3-b1ce-ab991116b3b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","1THREEPIO to the love of the love of be show thee thee in i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 6. Membuat Perintah Untuk 100 Kata Selanjutnya**\n","\n","**Logika Kode:**\n","Ini definisi fungsi `predict_next_words` buat nge-tes model kita. Fungsi ini bakal nge-generasi teks baru.\n","1.  `for _ in range(next_words):`: Nge-*loop* sebanyak `next_words` (misal 100 kali).\n","2.  `token_list = tokenizer.texts_to_sequences([seed_text])[0]`: Ngubah `seed_text` (teks awal) jadi urutan angka.\n","3.  `token_list = pad_sequences(...)`: Nyiapin inputnya. Di-*padding* di depan biar panjangnya pas (10 token) kayak data `xs`.\n","4.  `predict_x = model.predict(token_list)`: Ini dia prediksinya. Model ngasih *output* probabilitas buat 2900 kata.\n","5.  `predicted = np.argmax(predict_x,axis=1)`: Milih kata dengan probabilitas tertinggi. `np.argmax` ngambil indeks (angka token) dari kata yang paling mungkin.\n","6.  `for word, index in tokenizer.word_index.items():`: Nge-*loop* kamus.\n","7.  `if index == predicted:`: Kalo indeksnya cocok sama hasil prediksi, kita nemu katanya.\n","8.  `output_word = word`: Simpen katanya.\n","9.  `seed_text += \" \" + output_word`: Nambahin kata yang baru ditebak ke `seed_text`.\n","10. *Loop* tadi ngulang lagi, tapi sekarang `seed_text`-nya udah lebih panjang satu kata. Modelnya jadi nebak kata berikutnya berdasarkan teks yang baru ditambahin.\n","11. `print(seed_text)`: Setelah *loop* 100 kali selesai, *print* hasil akhirnya.\n","\n","**Output/Efek:**\n","Gak ada *output* pas sel ini dijalanin, karena ini cuma definisi fungsi."],"metadata":{"id":"sXYMP9xWtw9p"}},{"cell_type":"code","source":["seed_text = 'why lovest thou that which not gladly'\n","generated_text = predict_next_words(seed_text, next_words)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i3W-xZh-H_ma","outputId":"07855bde-e5bf-40de-a3a4-2c3bc81645da"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step\n","why lovest thou that which not gladly thee in thee love the love of show thee in thee in you thee in the love of show thee me thee in i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i thee i\n"]}]},{"cell_type":"markdown","source":["### **Penjelasan Logika & Output: 7. Output Artikel dengan Seed Text**\n","\n","**Logika Kode:**\n","Ini bagian ngejalanin fungsi prediksi yang udah kita buat.\n","1.  `seed_text = '1THREEPIO'`: Nentuin teks awal buat mancing model. *Catatan: '1THREEPIO' ini kayaknya kata yang gak ada di dataset Shakespeare, jadi hasilnya bakal aneh.*\n","2.  `next_words = 100`: Nyuruh model buat nge-generasi 100 kata baru.\n","3.  `generated_text = predict_next_words(...)`: Manggil fungsinya.\n","4.  Sel berikutnya, dicoba lagi pake *seed text* yang lebih masuk akal: `seed_text = 'why lovest thou that which not gladly'`.\n","\n","**Output/Efek:**\n","* Pertama, dia bakal nge-print *log* `model.predict` 100 kali (karena di dalem *loop*).\n","* Terus, dia bakal nge-print teks hasil generasinya.\n","* Buat *seed* `'1THREEPIO'`, hasilnya: `1THREEPIO to the love of the love of be show thee...` Ini keliatan modelnya \"macet\" (*looping*), nebak kata 'thee' dan 'i' terus-terusan. Ini wajar karena *seed text*-nya aneh dan *training*-nya baru 10 *epoch*.\n","* Buat *seed* `'why lovest thou...'`, hasilnya: `why lovest thou that which not gladly thee in thee love the love of show thee...` Hasilnya masih sama-sama \"macet\", nunjukkin modelnya masih perlu *training* jauh lebih lama (lebih dari 100 *epoch*) biar bisa ngasih hasil yang lebih variatif."],"metadata":{"id":"O-MQiAAXtx7a"}}]}