{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# PENGENALAN GAN\n","Rizky Ramdhani Koswara - 11122300 - 4KA25\n","> Add blockquote\n","\n"],"metadata":{"id":"3e1OUdkKYuK4"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OsQYyCbIv9VL"},"outputs":[],"source":["from keras.datasets import mnist"]},{"cell_type":"markdown","source":["Penjelasan: Blok ini hanya berisi satu baris kode yang berfungsi untuk mengimpor dataset MNIST dari library Keras. Dataset MNIST adalah kumpulan data populer yang berisi 70.000 gambar hitam-putih tulisan tangan angka dari 0 hingga 9. Dataset ini sering digunakan sebagai \"Hello, World!\" dalam dunia machine learning untuk tugas pengenalan gambar."],"metadata":{"id":"DdojJB2Hq9Yg"}},{"cell_type":"code","source":["from tensorflow.keras import Sequential\n","from keras.layers import BatchNormalization, Dense, Reshape, Flatten\n","from keras.layers import LeakyReLU\n","from tensorflow.keras.optimizers import Adam\n","import numpy as np"],"metadata":{"id":"iQOgiHwVwH_6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Penjelasan: Blok ini mengimpor semua komponen yang dibutuhkan untuk membangun model jaringan saraf tiruan (neural network) dengan Keras.\n","\n","Sequential: Ini adalah model dasar di Keras yang memungkinkan kita membangun jaringan saraf secara berurutan, lapisan demi lapisan.\n","\n","Dense, Reshape, Flatten: Ini adalah jenis-jenis lapisan (layer) yang akan digunakan.\n","\n","Dense: Lapisan yang terhubung sepenuhnya (fully connected), di mana setiap neuron terhubung ke semua neuron di lapisan sebelumnya.\n","\n","Flatten: Mengubah data multi-dimensi (seperti gambar 28x28) menjadi satu dimensi (vektor).\n","\n","Reshape: Mengubah bentuk (dimensi) data ke bentuk yang diinginkan.\n","\n","BatchNormalization: Sebuah teknik untuk menstabilkan dan mempercepat proses pelatihan dengan menormalisasi input dari setiap lapisan.\n","\n","LeakyReLU: Fungsi aktivasi yang merupakan varian dari ReLU. Ini sering digunakan pada GAN karena membantu mengatasi masalah \"dying ReLU\" dan menjaga aliran gradien selama pelatihan.\n","\n","Adam: Salah satu algoritma optimisasi yang paling populer untuk melatih model deep learning.\n","\n","numpy: Library standar untuk komputasi numerik di Python, digunakan di sini untuk operasi matematika pada array."],"metadata":{"id":"itwlQCfTq-wj"}},{"cell_type":"code","source":["## mendefinisikan variable gambar\n","## ukuran dimensi\n","img_width = 28\n","img_height = 28\n","channels = 1\n","img_shape = (img_width, img_height, channels)\n","latent_dim = 100\n","adam = Adam(learning_rate=0.0001)"],"metadata":{"id":"McKNWeZozQgO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Penjelasan: Blok ini mendefinisikan variabel-variabel penting yang akan digunakan di seluruh program.\n","\n","img_width, img_height, channels: Menentukan dimensi gambar dari dataset MNIST (lebar 28 piksel, tinggi 28 piksel, dan 1 channel warna karena gambarnya hitam-putih).\n","\n","img_shape: Menggabungkan dimensi tersebut menjadi satu tuple (28, 28, 1), yang akan digunakan untuk mendefinisikan bentuk input dan output model.\n","\n","latent_dim: Menentukan ukuran \"ruang laten\" atau dimensi dari vektor input acak (noise) untuk Generator. Angka 100 berarti Generator akan membuat gambar dari input acak yang terdiri dari 100 angka.\n","\n","adam: Menginisialisasi optimizer Adam dengan learning_rate (laju belajar) yang diatur cukup kecil (0.0001) untuk membantu pelatihan GAN agar lebih stabil."],"metadata":{"id":"psV0PlsjrGjJ"}},{"cell_type":"code","source":["def build_generator():\n","  model = Sequential()\n","\n","  model.add(Dense(256, input_dim=latent_dim))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(BatchNormalization(momentum=0.8))\n","\n","  model.summary()\n","  return model"],"metadata":{"id":"LmUAusmF0RV4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator = build_generator()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"USxp93kM1gSq","outputId":"a40d5367-3075-4bfc-8876-0d34deabd8d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense (Dense)               (None, 256)               25856     \n","                                                                 \n"," leaky_re_lu (LeakyReLU)     (None, 256)               0         \n","                                                                 \n"," batch_normalization (Batch  (None, 256)               1024      \n"," Normalization)                                                  \n","                                                                 \n","=================================================================\n","Total params: 26880 (105.00 KB)\n","Trainable params: 26368 (103.00 KB)\n","Non-trainable params: 512 (2.00 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["def build_generator():\n","  model = Sequential()\n","\n","  model.add(Dense(256, input_dim=latent_dim))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(BatchNormalization(momentum=0.8))\n","\n","  model.add(Dense(512))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(BatchNormalization(momentum=0.8))\n","\n","  model.add(Dense(1024))\n","  model.add(LeakyReLU(alpha=0.2))\n","  model.add(BatchNormalization(momentum=0.8))\n","\n","  model.add(Dense(np.prod(img_shape), activation='tanh'))\n","  model.add(Reshape(img_shape))\n","\n","  model.summary()\n","  return model"],"metadata":{"id":"ODH1vjON1jcZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["generator = build_generator()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqg3hUTn2CK5","outputId":"c9d3c200-b347-4cc2-b061-90a46afdfc0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             (None, 256)               25856     \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n"," batch_normalization_1 (Bat  (None, 256)               1024      \n"," chNormalization)                                                \n","                                                                 \n"," dense_2 (Dense)             (None, 512)               131584    \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 512)               0         \n","                                                                 \n"," batch_normalization_2 (Bat  (None, 512)               2048      \n"," chNormalization)                                                \n","                                                                 \n"," dense_3 (Dense)             (None, 1024)              525312    \n","                                                                 \n"," leaky_re_lu_3 (LeakyReLU)   (None, 1024)              0         \n","                                                                 \n"," batch_normalization_3 (Bat  (None, 1024)              4096      \n"," chNormalization)                                                \n","                                                                 \n"," dense_4 (Dense)             (None, 784)               803600    \n","                                                                 \n"," reshape (Reshape)           (None, 28, 28, 1)         0         \n","                                                                 \n","=================================================================\n","Total params: 1493520 (5.70 MB)\n","Trainable params: 1489936 (5.68 MB)\n","Non-trainable params: 3584 (14.00 KB)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Penjelasan: Blok ini mendefinisikan arsitektur untuk Generator. Tugas Generator adalah mengambil input acak (noise) berdimensi latent_dim (100) dan mengubahnya menjadi sebuah gambar berukuran 28x28x1.\n","\n","Model ini secara bertahap meningkatkan dimensi dari input 100 menjadi 256, lalu 512, dan 1024 melalui lapisan Dense. Setiap lapisan Dense diikuti oleh LeakyReLU dan BatchNormalization untuk menjaga stabilitas.\n","\n","Lapisan Dense terakhir menghasilkan output sejumlah total piksel pada gambar (28*28*1 = 784) dengan fungsi aktivasi tanh. tanh digunakan agar nilai piksel output berada di rentang [-1, 1], yang merupakan praktik umum dalam GAN.\n","\n","Lapisan Reshape terakhir mengubah vektor 784 piksel tersebut menjadi bentuk gambar yang sesuai, yaitu (28, 28, 1).\n","\n","model.summary() mencetak ringkasan arsitektur model yang telah dibuat."],"metadata":{"id":"R_BfTe9wrmlz"}},{"cell_type":"code","source":["def build_discriminator():\n","  model = Sequential()\n","\n","  model.add(Flatten(input_shape=img_shape))\n","  model.add(Dense(512))\n","  model.add(LeakyReLU(alpha=0.2))\n","\n","  model.add(Dense(256))\n","  model.add(LeakyReLU(alpha=0.2))\n","\n","  model.summary()\n","  return model\n","\n","discriminator = build_discriminator()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EvLzuRHU2Dnv","outputId":"f580f7fb-5e02-481e-9b86-9ad87a75ed51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," flatten (Flatten)           (None, 784)               0         \n","                                                                 \n"," dense_5 (Dense)             (None, 512)               401920    \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 512)               0         \n","                                                                 \n"," dense_6 (Dense)             (None, 256)               131328    \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 256)               0         \n","                                                                 \n","=================================================================\n","Total params: 533248 (2.03 MB)\n","Trainable params: 533248 (2.03 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Penjelasan: Blok ini mendefinisikan arsitektur untuk Diskriminator. Tugas Diskriminator adalah menerima sebuah gambar (baik asli dari dataset atau palsu dari Generator) dan memutuskan apakah gambar itu asli atau palsu.\n","\n","Lapisan Flatten pertama kali meratakan gambar input (28, 28, 1) menjadi vektor satu dimensi (784 piksel).\n","\n","Lapisan Dense selanjutnya (512 dan 256 neuron) berfungsi sebagai \"otak\" dari diskriminator untuk mengekstraksi fitur dari gambar dan melakukan klasifikasi.\n","\n","Penting: Arsitektur ini belum lengkap. Seharusnya ada lapisan output terakhir seperti Dense(1, activation='sigmoid') untuk menghasilkan satu nilai probabilitas (antara 0 untuk \"palsu\" dan 1 untuk \"asli\")."],"metadata":{"id":"v9BOfrDDrrfS"}},{"cell_type":"code","source":["discriminator.compile(loss='binary_crossentropy', optimizer='adam')\n","\n","GAN = Sequential()\n","discriminator.trainable = False\n","GAN.add(generator)\n","GAN.add(discriminator)\n","\n","GAN.compile(loss='binary_crossentropy', optimizer='adam')"],"metadata":{"id":"bDzR0rFL2bw6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Penjelasan: Ini adalah blok yang sangat penting di mana model Generator dan Diskriminator digabungkan untuk membentuk model GAN utuh.\n","\n","discriminator.compile(...): Pertama, Diskriminator dikompilasi sebagai model mandiri. Ia menggunakan binary_crossentropy sebagai fungsi kerugian, karena tugasnya adalah klasifikasi biner (asli vs. palsu).\n","\n","GAN = Sequential(): Sebuah model Sequential baru dibuat untuk menampung keseluruhan arsitektur GAN.\n","\n","discriminator.trainable = False: Ini adalah trik kunci dalam pelatihan GAN. Ketika kita melatih Generator, kita tidak ingin bobot Diskriminator ikut berubah. Dengan mengatur ini ke False, kita \"membekukan\" Diskriminator. Tujuannya adalah agar Generator bisa belajar dari feedback Diskriminator tanpa mengubah Diskriminator itu sendiri.\n","\n","GAN.add(generator) dan GAN.add(discriminator): Generator dan Diskriminator (yang sudah dibekukan) ditambahkan ke model GAN secara berurutan. Ini berarti output dari Generator akan langsung menjadi input bagi Diskriminator.\n","\n","GAN.compile(...): Model GAN gabungan ini kemudian dikompilasi. Tujuannya adalah untuk melatih Generator agar menghasilkan gambar yang bisa menipu Diskriminator sehingga Diskriminator mengklasifikasikannya sebagai \"asli\"."],"metadata":{"id":"9-3Ujk8zrtZg"}},{"cell_type":"code","source":[],"metadata":{"id":"pYpXbNOL2wD_"},"execution_count":null,"outputs":[]}]}